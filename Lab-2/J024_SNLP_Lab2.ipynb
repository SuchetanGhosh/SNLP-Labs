{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c538c64-2e06-42f2-9d9a-d60d8b24e020",
   "metadata": {},
   "source": [
    "# WORD2VEC SIMILAR WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6059476-569c-416b-b514-e585e3db3db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'computer': [('computers', 0.7979379296302795),\n",
       "   ('laptop', 0.6640492677688599),\n",
       "   ('laptop_computer', 0.6548868417739868),\n",
       "   ('Computer', 0.6473336219787598),\n",
       "   ('com_puter', 0.6082081198692322)],\n",
       "  'science': [('faith_Jezierski', 0.6965421438217163),\n",
       "   ('sciences', 0.6821076273918152),\n",
       "   ('biology', 0.6775783896446228),\n",
       "   ('scientific', 0.6535003185272217),\n",
       "   ('mathematics', 0.6300910115242004)],\n",
       "  'music': [('classical_music', 0.7197794318199158),\n",
       "   ('jazz', 0.6834639310836792),\n",
       "   ('Music', 0.6595720648765564),\n",
       "   ('Without_Donny_Kirshner', 0.6416223645210266),\n",
       "   ('songs', 0.6396344304084778)],\n",
       "  'happy': [('glad', 0.7408890724182129),\n",
       "   ('pleased', 0.6632170677185059),\n",
       "   ('ecstatic', 0.6626912951469421),\n",
       "   ('overjoyed', 0.6599285006523132),\n",
       "   ('thrilled', 0.6514049172401428)],\n",
       "  'river': [('creek', 0.7994444370269775),\n",
       "   ('lake', 0.7919586300849915),\n",
       "   ('rivers', 0.7777559757232666),\n",
       "   ('riverbank', 0.7283666729927063),\n",
       "   ('canal', 0.722176194190979)]},\n",
       " {'Paris - France + Germany': [('Berlin', 0.7644001841545105)],\n",
       "  'boy - girl + queen': [('king', 0.7298421859741211)],\n",
       "  'strong - strength + weak': [('sluggish', 0.5477452278137207)]})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load the pretrained word2vec-google-news-300 model\n",
    "pretrained_model = api.load('word2vec-google-news-300')\n",
    "\n",
    "# List of chosen words\n",
    "words = ['computer', 'science', 'music', 'happy', 'river']\n",
    "\n",
    "# Finding similar words for each chosen word\n",
    "similar_words = {word: pretrained_model.most_similar(word, topn=5) for word in words}\n",
    "\n",
    "# Performing analogy tests\n",
    "analogies = {\n",
    "    \"Paris - France + Germany\": pretrained_model.most_similar(positive=['Germany', 'Paris'], negative=['France'], topn=1),\n",
    "    \"boy - girl + queen\": pretrained_model.most_similar(positive=['boy', 'queen'], negative=['girl'], topn=1),\n",
    "    \"strong - strength + weak\": pretrained_model.most_similar(positive=['weak', 'strong'], negative=['strength'], topn=1)\n",
    "}\n",
    "\n",
    "similar_words, analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5618528-8aab-4dc6-9b1a-4714b4e8a0f2",
   "metadata": {},
   "source": [
    "# MOVIE REVIEW SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073d79b-03a1-402c-bf09-b7b8943af5b6",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING AND EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fad2a97-baba-48d6-b8ed-d701622f7b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "imdb = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Display basic information and statistics\n",
    "imdb.info()\n",
    "imdb.describe()\n",
    "imdb['sentiment'].value_counts()\n",
    "\n",
    "# Display some sample reviews\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c120dc-a6d6-4bf6-96b8-55ff8cdf1009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identical rows = 418\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of identical rows =\",len(imdb[imdb.duplicated()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6481b82d-bf66-4469-a136-92e303eda988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identical rows = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49577</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49578</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49579</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49580</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49581</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49577  I thought this movie did a down right good job...  positive\n",
       "49578  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49579  I am a Catholic taught in parochial elementary...  negative\n",
       "49580  I'm going to have to disagree with the previou...  negative\n",
       "49581  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[49582 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = imdb.drop_duplicates().reset_index(drop=True)\n",
    "print(\"Number of identical rows =\",len(imdb[imdb.duplicated()]))\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4f951d-afa4-4f3c-9362-5421b9bedbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suchi\\AppData\\Local\\Temp\\ipykernel_43532\\3255259064.py:23: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>probably alltime favorite movie story selfless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sure would like see resurrection dated seahunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>show amazing fresh innovative idea first aired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>encouraged positive comments film looking forw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>like original gut wrenching laughter like movi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "5  Probably my all-time favorite movie, a story o...  positive   \n",
       "6  I sure would like to see a resurrection of a u...  positive   \n",
       "7  This show was an amazing, fresh & innovative i...  negative   \n",
       "8  Encouraged by the positive comments about this...  negative   \n",
       "9  If you like original gut wrenching laughter yo...  positive   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  one reviewers mentioned watching oz episode yo...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically theres family little boy jake thinks...  \n",
       "4  petter matteis love time money visually stunni...  \n",
       "5  probably alltime favorite movie story selfless...  \n",
       "6  sure would like see resurrection dated seahunt...  \n",
       "7  show amazing fresh innovative idea first aired...  \n",
       "8  encouraged positive comments film looking forw...  \n",
       "9  like original gut wrenching laughter like movi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define the text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags using html.parser explicitly\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the text data\n",
    "imdb['preprocessed_text'] = imdb['review'].apply(preprocess_text)\n",
    "\n",
    "# Display dataframe with added column\n",
    "imdb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6bb60dd-96d6-491d-a55b-8fa896a02ffd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m skipgram_metrics \u001b[38;5;241m=\u001b[39m train_and_evaluate(skipgram_model)\n\u001b[0;32m     41\u001b[0m cbow_metrics \u001b[38;5;241m=\u001b[39m train_and_evaluate(cbow_model)\n\u001b[1;32m---> 42\u001b[0m pretrained_metrics \u001b[38;5;241m=\u001b[39m train_and_evaluate(pretrained_model)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# optimized_skipgram_metrics = train_and_evaluate(optimized_skipgram_model)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# optimized_cbow_metrics = train_and_evaluate(optimized_cbow_model)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Create a summary table\u001b[39;00m\n\u001b[0;32m     47\u001b[0m metrics_summary \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkip-gram\u001b[39m\u001b[38;5;124m'\u001b[39m: skipgram_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCBoW\u001b[39m\u001b[38;5;124m'\u001b[39m: cbow_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# 'Optimized CBoW': optimized_cbow_metrics['weighted avg'],\u001b[39;00m\n\u001b[0;32m     53\u001b[0m })\n",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate\u001b[39m(model):\n\u001b[1;32m---> 30\u001b[0m     X_train_vectors \u001b[38;5;241m=\u001b[39m get_vector_representation(X_train, model)\n\u001b[0;32m     31\u001b[0m     X_test_vectors \u001b[38;5;241m=\u001b[39m get_vector_representation(X_test, model)\n\u001b[0;32m     33\u001b[0m     clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m, in \u001b[0;36mget_vector_representation\u001b[1;34m(reviews, model)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m reviews:\n\u001b[0;32m     20\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m review\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m---> 21\u001b[0m     vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([model\u001b[38;5;241m.\u001b[39mwv[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mwv])\n\u001b[0;32m     22\u001b[0m     vectors\u001b[38;5;241m.\u001b[39mappend(vector)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vectors\n",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m reviews:\n\u001b[0;32m     20\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m review\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m---> 21\u001b[0m     vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([model\u001b[38;5;241m.\u001b[39mwv[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mwv])\n\u001b[0;32m     22\u001b[0m     vectors\u001b[38;5;241m.\u001b[39mappend(vector)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vectors\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenize cleaned reviews\n",
    "tokenized_reviews = [review.split() for review in imdb['preprocessed_text']]\n",
    "\n",
    "# Train Word2Vec model using Skip-gram\n",
    "skipgram_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=2, sg=1)\n",
    "\n",
    "# Train Word2Vec model using CBoW\n",
    "cbow_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=2, sg=0)\n",
    "\n",
    "# pretrained_model (word2vec-google-news-300) is already loaded in notebook\n",
    "\n",
    "def get_vector_representation(reviews, model):\n",
    "    vectors = []\n",
    "    for review in reviews:\n",
    "        tokens = review.split()\n",
    "        vector = sum([model.wv[word] for word in tokens if word in model.wv])\n",
    "        vectors.append(vector)\n",
    "    return vectors\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(imdb['preprocessed_text'], imdb['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate(model):\n",
    "    X_train_vectors = get_vector_representation(X_train, model)\n",
    "    X_test_vectors = get_vector_representation(X_test, model)\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train_vectors, y_train)\n",
    "    y_pred = clf.predict(X_test_vectors)\n",
    "    \n",
    "    return classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Report metrics for each model\n",
    "skipgram_metrics = train_and_evaluate(skipgram_model)\n",
    "cbow_metrics = train_and_evaluate(cbow_model)\n",
    "pretrained_metrics = train_and_evaluate(pretrained_model)\n",
    "# optimized_skipgram_metrics = train_and_evaluate(optimized_skipgram_model)\n",
    "# optimized_cbow_metrics = train_and_evaluate(optimized_cbow_model)\n",
    "\n",
    "# Create a summary table\n",
    "metrics_summary = pd.DataFrame({\n",
    "    'Skip-gram': skipgram_metrics['weighted avg'],\n",
    "    'CBoW': cbow_metrics['weighted avg'],\n",
    "    'Pretrained': pretrained_metrics['weighted avg']\n",
    "    # 'Optimized Skip-gram': optimized_skipgram_metrics['weighted avg'],\n",
    "    # 'Optimized CBoW': optimized_cbow_metrics['weighted avg'],\n",
    "})\n",
    "\n",
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f05694f-cdc1-476f-b31d-6fc01f70a72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
